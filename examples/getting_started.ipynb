{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with RESOLVE\n",
    "\n",
    "This notebook demonstrates how to use RESOLVE to predict plot-level environmental attributes from species composition data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install resolve-ml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import RESOLVE\n",
    "import resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sample Data\n",
    "\n",
    "RESOLVE requires two CSV files:\n",
    "1. **Header file**: One row per plot with plot ID, coordinates, covariates, and target variables\n",
    "2. **Species file**: One row per species-plot occurrence with species ID, plot ID, and abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example header data (plot-level attributes)\n",
    "header_df = pd.DataFrame({\n",
    "    'plot_id': [f'P{i:03d}' for i in range(1, 101)],\n",
    "    'longitude': np.random.uniform(4.0, 5.0, 100),\n",
    "    'latitude': np.random.uniform(50.5, 51.0, 100),\n",
    "    'elevation': np.random.uniform(50, 200, 100),\n",
    "    'biomass': np.random.exponential(50, 100),  # Target: regression\n",
    "    'habitat': np.random.choice(['forest', 'grassland', 'wetland'], 100)  # Target: classification\n",
    "})\n",
    "\n",
    "print(\"Header data shape:\", header_df.shape)\n",
    "header_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example species data (species occurrences per plot)\n",
    "species_list = [\n",
    "    ('Quercus robur', 'Quercus', 'Fagaceae'),\n",
    "    ('Fagus sylvatica', 'Fagus', 'Fagaceae'),\n",
    "    ('Pinus sylvestris', 'Pinus', 'Pinaceae'),\n",
    "    ('Betula pendula', 'Betula', 'Betulaceae'),\n",
    "    ('Acer pseudoplatanus', 'Acer', 'Sapindaceae'),\n",
    "    ('Fraxinus excelsior', 'Fraxinus', 'Oleaceae'),\n",
    "    ('Carpinus betulus', 'Carpinus', 'Betulaceae'),\n",
    "    ('Tilia cordata', 'Tilia', 'Malvaceae'),\n",
    "]\n",
    "\n",
    "# Generate random species occurrences\n",
    "species_records = []\n",
    "for plot_id in header_df['plot_id']:\n",
    "    n_species = np.random.randint(3, 8)\n",
    "    selected = np.random.choice(len(species_list), n_species, replace=False)\n",
    "    for idx in selected:\n",
    "        name, genus, family = species_list[idx]\n",
    "        species_records.append({\n",
    "            'plot_id': plot_id,\n",
    "            'species': name,\n",
    "            'cover': np.random.uniform(5, 80),\n",
    "            'genus': genus,\n",
    "            'family': family\n",
    "        })\n",
    "\n",
    "species_df = pd.DataFrame(species_records)\n",
    "print(\"Species data shape:\", species_df.shape)\n",
    "species_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to temporary CSV files\n",
    "header_path = Path('temp_header.csv')\n",
    "species_path = Path('temp_species.csv')\n",
    "\n",
    "header_df.to_csv(header_path, index=False)\n",
    "species_df.to_csv(species_path, index=False)\n",
    "\n",
    "print(f\"Saved header to {header_path}\")\n",
    "print(f\"Saved species to {species_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset with Role Mapping\n",
    "\n",
    "RESOLVE uses role mapping to understand your data structure. Map your column names to semantic roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column role mapping\n",
    "roles = {\n",
    "    'plot_id': 'plot_id',          # Plot identifier in header\n",
    "    'species_id': 'species',        # Species name column in species file\n",
    "    'species_plot_id': 'plot_id',   # Plot identifier in species file\n",
    "    'abundance': 'cover',           # Abundance/cover values\n",
    "    'coords_lon': 'longitude',      # Longitude column\n",
    "    'coords_lat': 'latitude',       # Latitude column\n",
    "    'taxonomy_genus': 'genus',      # Genus column\n",
    "    'taxonomy_family': 'family'     # Family column\n",
    "}\n",
    "\n",
    "# Define target variables\n",
    "targets = {\n",
    "    'biomass': {\n",
    "        'column': 'biomass',\n",
    "        'task': 'regression',\n",
    "        'transform': 'log1p'  # Log-transform for positive values\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = resolve.Dataset.from_csv(\n",
    "    header_path=str(header_path),\n",
    "    species_path=str(species_path),\n",
    "    roles=roles,\n",
    "    targets=targets\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Plots: {dataset.schema.n_plots}\")\n",
    "print(f\"  Species: {dataset.schema.n_species}\")\n",
    "print(f\"  Has coordinates: {dataset.schema.has_coordinates}\")\n",
    "print(f\"  Has taxonomy: {dataset.schema.has_taxonomy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training\n",
    "trainer = resolve.Trainer(\n",
    "    dataset,\n",
    "    hidden_dims=[512, 256, 128, 64],\n",
    "    species_encoding='hash',  # or 'embed' for learned embeddings\n",
    "    hash_dim=32,\n",
    "    device='cpu'  # Use 'cuda' for GPU acceleration\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "result = trainer.fit(\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Best epoch: {result.best_epoch}\")\n",
    "print(f\"Best loss: {result.best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final metrics\n",
    "for target_name, metrics in result.final_metrics.items():\n",
    "    print(f\"\\n{target_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training data (for demonstration)\n",
    "predictions = trainer.predict(dataset)\n",
    "\n",
    "print(\"Prediction keys:\", list(predictions.predictions.keys()))\n",
    "print(\"Biomass predictions shape:\", predictions.predictions['biomass'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions vs actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "actual = header_df['biomass'].values\n",
    "predicted = predictions.predictions['biomass'].numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual, predicted, alpha=0.6)\n",
    "plt.plot([0, max(actual)], [0, max(actual)], 'r--', label='1:1 line')\n",
    "plt.xlabel('Actual Biomass')\n",
    "plt.ylabel('Predicted Biomass')\n",
    "plt.title('RESOLVE Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence-Based Filtering\n",
    "\n",
    "RESOLVE tracks the fraction of unknown species per plot. Use this for confidence-based filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unknown fraction (0 = all species known, 1 = all unknown)\n",
    "unknown_frac = predictions.unknown_fraction.numpy()\n",
    "confidence = 1 - unknown_frac\n",
    "\n",
    "print(f\"Confidence range: [{confidence.min():.2f}, {confidence.max():.2f}]\")\n",
    "print(f\"Mean confidence: {confidence.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter predictions by confidence threshold\n",
    "threshold = 0.5\n",
    "high_confidence_mask = confidence >= threshold\n",
    "\n",
    "print(f\"Plots with confidence >= {threshold}: {high_confidence_mask.sum()} / {len(confidence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = Path('resolve_model.pt')\n",
    "trainer.save(str(model_path))\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for inference\n",
    "predictor = resolve.Predictor.load(str(model_path))\n",
    "\n",
    "# Make predictions with loaded model\n",
    "new_predictions = predictor.predict(dataset)\n",
    "print(\"Predictions from loaded model:\", new_predictions.predictions['biomass'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove temporary files\n",
    "header_path.unlink(exist_ok=True)\n",
    "species_path.unlink(exist_ok=True)\n",
    "model_path.unlink(exist_ok=True)\n",
    "print(\"Temporary files cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Multi-task learning**: Add multiple targets (regression + classification)\n",
    "- **GPU acceleration**: Use `device='cuda'` for larger datasets\n",
    "- **Hyperparameter tuning**: Experiment with `hidden_dims`, `hash_dim`, `species_encoding`\n",
    "- **Loss configuration**: Try `lossConfig='combined'` for phased training\n",
    "\n",
    "See the [documentation](https://github.com/gcol33/resolve) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
